<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Losing My First Machine Learning Competition</title>
    <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/vega@5"></script>
    <script src="https://cdn.jsdelivr.net/npm/vega-lite@5"></script>
    <script src="https://cdn.jsdelivr.net/npm/vega-embed@6"></script>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Consolas', 'Monaco', 'Courier New', monospace, -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            line-height: 1.6;
            color: #333;
            background-color: #f5f5f5;
            background-image: 
                linear-gradient(45deg, #e0e0e0 25%, transparent 25%),
                linear-gradient(-45deg, #e0e0e0 25%, transparent 25%),
                linear-gradient(45deg, transparent 75%, #e0e0e0 75%),
                linear-gradient(-45deg, transparent 75%, #e0e0e0 75%);
            background-size: 20px 20px;
            background-position: 0 0, 0 10px, 10px -10px, -10px 0px;
        }

        .container {
            max-width: 900px;
            margin: 0 auto;
            padding: 20px;
        }

        .header {
            background-color: white;
            padding: 20px;
            margin-bottom: 30px;
            border-radius: 8px;
            box-shadow: 0 2px 15px rgba(0,0,0,0.1);
            border-left: 5px solid #4CAF50;
            position: relative;
            overflow: hidden;
        }

        .header::after {
            content: "";
            position: absolute;
            top: 0;
            right: 0;
            width: 100px;
            height: 100px;
            background: url('data:image/svg+xml;utf8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 100 100"><path fill="%234CAF50" opacity="0.1" d="M30,10 Q50,0 70,10 Q90,20 90,40 Q90,60 70,70 Q50,80 30,70 Q10,60 10,40 Q10,20 30,10 Z"/></svg>') no-repeat;
            background-size: contain;
        }

        .home-btn {
            display: inline-block;
            padding: 8px 16px;
            background: linear-gradient(135deg, #007acc, #00bcd4);
            color: white;
            text-decoration: none;
            border-radius: 4px;
            font-size: 14px;
            margin-bottom: 20px;
            transition: transform 0.3s, box-shadow 0.3s;
            box-shadow: 0 2px 5px rgba(0,0,0,0.1);
            border: none;
            font-family: 'Courier New', monospace;
        }

        .home-btn:hover {
            transform: translateY(-2px);
            box-shadow: 0 4px 8px rgba(0,0,0,0.2);
        }

        h1 {
            color: #2c3e50;
            font-size: 2.5em;
            margin-bottom: 10px;
            font-weight: 700;
            background: linear-gradient(90deg, #4CAF50, #2196F3);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            font-family: 'Courier New', monospace;
        }

        .content {
            background-color: white;
            padding: 30px;
            border-radius: 8px;
            box-shadow: 0 2px 15px rgba(0,0,0,0.1);
            margin-bottom: 20px;
            position: relative;
        }

        .content::before {
            content: "";
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 5px;
            background: linear-gradient(90deg, #4CAF50, #2196F3, #FFC107, #FF5722);
        }

        h2 {
            color: #34495e;
            font-size: 1.8em;
            margin: 30px 0 15px 0;
            padding-bottom: 10px;
            border-bottom: 2px solid #ecf0f1;
            font-family: 'Courier New', monospace;
        }

        .section-index {
            background: linear-gradient(135deg, #2196F3, #4CAF50);
            color: white;
            padding: 3px 8px;
            border-radius: 3px;
            font-size: 0.9em;
            margin-right: 10px;
            font-family: 'Courier New', monospace;
            box-shadow: 0 2px 3px rgba(0,0,0,0.1);
        }

        p {
            margin-bottom: 15px;
            text-align: justify;
            font-family: 'Consolas', monospace;
        }

        .notebook-info {
            background-color: #f8f9fa;
            border-left: 4px solid #007acc;
            padding: 15px;
            margin: 20px 0;
            border-radius: 0 4px 4px 0;
            font-family: 'Courier New', monospace;
            position: relative;
        }

        .notebook-info::before {
            content: "📊";
            position: absolute;
            left: -30px;
            top: 50%;
            transform: translateY(-50%);
            font-size: 20px;
        }

        .notebook-info strong {
            color: #007acc;
        }

        .tools {
            font-style: italic;
            color: #666;
            font-size: 0.9em;
            display: block;
            margin-top: 5px;
        }

        a {
            color: #2196F3;
            text-decoration: none;
            font-weight: bold;
            position: relative;
        }

        a:hover {
            text-decoration: underline;
        }

        a::after {
            content: "↗";
            font-size: 0.8em;
            margin-left: 2px;
        }

        .highlight {
            background-color: #fff3cd;
            padding: 2px 4px;
            border-radius: 3px;
            font-family: 'Courier New', monospace;
        }

        .lesson-box {
            background-color: #e8f5e8;
            border-left: 4px solid #28a745;
            padding: 15px;
            margin: 20px 0;
            border-radius: 0 4px 4px 0;
            font-family: 'Courier New', monospace;
            position: relative;
        }

        .lesson-box::before {
            content: "🧠";
            position: absolute;
            left: -30px;
            top: 50%;
            transform: translateY(-50%);
            font-size: 20px;
        }

        .lesson-box strong {
            color: #155724;
        }

        ul, ol {
            margin: 15px 0 15px 30px;
            font-family: 'Consolas', monospace;
        }

        li {
            margin-bottom: 8px;
            position: relative;
        }

        li::before {
            content: "▹";
            color: #4CAF50;
            position: absolute;
            left: -20px;
        }

        .footer {
            text-align: center;
            padding: 20px;
            color: #666;
            font-size: 0.9em;
            font-family: 'Courier New', monospace;
        }

        /* ML-themed additions */
        .model-visualization {
            margin: 25px 0;
            padding: 15px;
            background-color: #f5f7fa;
            border-radius: 8px;
            border: 1px solid #e0e0e0;
        }

        .leaderboard {
            width: 100%;
            border-collapse: collapse;
            margin: 20px 0;
            font-family: 'Courier New', monospace;
        }

        .leaderboard th {
            background-color: #4CAF50;
            color: white;
            padding: 10px;
            text-align: left;
        }

        .leaderboard tr:nth-child(even) {
            background-color: #f2f2f2;
        }

        .leaderboard tr:hover {
            background-color: #e0e0e0;
        }

        .leaderboard td {
            padding: 8px 10px;
            border-bottom: 1px solid #ddd;
        }

        .leaderboard .highlight-row {
            background-color: #fff3cd !important;
            font-weight: bold;
        }

        .code-block {
            background-color: #282c34;
            color: #abb2bf;
            padding: 15px;
            border-radius: 5px;
            overflow-x: auto;
            margin: 20px 0;
            font-family: 'Consolas', 'Monaco', 'Courier New', monospace;
            font-size: 0.9em;
        }

        .code-block .keyword {
            color: #c678dd;
        }

        .code-block .function {
            color: #61afef;
        }

        .code-block .string {
            color: #98c379;
        }

        .code-block .comment {
            color: #5c6370;
            font-style: italic;
        }

        .code-block .number {
            color: #d19a66;
        }

        .interactive-demo {
            margin: 25px 0;
            padding: 20px;
            background-color: #f8f9fa;
            border-radius: 8px;
            border: 1px dashed #007acc;
        }

        .interactive-demo h3 {
            margin-top: 0;
            color: #007acc;
            font-family: 'Courier New', monospace;
        }

        .interactive-demo button {
            background-color: #4CAF50;
            color: white;
            border: none;
            padding: 8px 16px;
            border-radius: 4px;
            cursor: pointer;
            margin: 10px 5px;
            font-family: 'Courier New', monospace;
        }

        .interactive-demo button:hover {
            background-color: #45a049;
        }

        .interactive-demo input {
            padding: 8px;
            border: 1px solid #ddd;
            border-radius: 4px;
            margin: 5px;
            font-family: 'Courier New', monospace;
        }

        .feature-importance {
            width: 100%;
            height: 300px;
            margin: 20px 0;
        }

        .confusion-matrix {
            display: inline-block;
            margin: 20px 0;
        }

        .confusion-matrix table {
            border-collapse: collapse;
        }

        .confusion-matrix td {
            width: 50px;
            height: 50px;
            text-align: center;
            border: 1px solid #333;
        }

        .confusion-matrix .true-positive {
            background-color: rgba(76, 175, 80, 0.7);
        }

        .confusion-matrix .false-positive {
            background-color: rgba(255, 152, 0, 0.7);
        }

        .confusion-matrix .false-negative {
            background-color: rgba(255, 152, 0, 0.7);
        }

        .confusion-matrix .true-negative {
            background-color: rgba(76, 175, 80, 0.7);
        }

        .ml-badge {
            display: inline-block;
            padding: 3px 8px;
            background-color: #e3f2fd;
            color: #1976d2;
            border-radius: 3px;
            font-size: 0.8em;
            margin-right: 5px;
            font-family: 'Courier New', monospace;
        }

        .terminal {
            background-color: #282c34;
            color: #abb2bf;
            padding: 15px;
            border-radius: 5px;
            font-family: 'Consolas', 'Monaco', 'Courier New', monospace;
            margin: 20px 0;
            position: relative;
        }

        .terminal::before {
            content: "Terminal";
            position: absolute;
            top: -10px;
            left: 10px;
            background-color: #282c34;
            color: #abb2bf;
            padding: 0 5px;
            font-size: 0.8em;
            border-radius: 3px 3px 0 0;
        }

        .terminal .prompt {
            color: #98c379;
        }

        .terminal .command {
            color: #61afef;
        }

        .terminal .output {
            color: #abb2bf;
        }

        .floating-ml-icons {
            position: fixed;
            bottom: 20px;
            right: 20px;
            z-index: 100;
        }

        .floating-ml-icons span {
            display: block;
            width: 50px;
            height: 50px;
            background-color: #4CAF50;
            color: white;
            border-radius: 50%;
            text-align: center;
            line-height: 50px;
            margin-bottom: 10px;
            font-size: 24px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.2);
            cursor: pointer;
            transition: transform 0.3s;
        }

        .floating-ml-icons span:hover {
            transform: scale(1.1);
        }

        .progress-bar {
            width: 100%;
            background-color: #e0e0e0;
            border-radius: 5px;
            margin: 20px 0;
            overflow: hidden;
        }

        .progress-bar-fill {
            height: 20px;
            background: linear-gradient(90deg, #4CAF50, #8BC34A);
            width: 0%;
            transition: width 1s;
            display: flex;
            align-items: center;
            justify-content: flex-end;
            padding-right: 10px;
            color: white;
            font-family: 'Courier New', monospace;
            font-size: 0.8em;
        }

        .hyperparams-table {
            width: 100%;
            border-collapse: collapse;
            margin: 20px 0;
            font-family: 'Courier New', monospace;
        }

        .hyperparams-table th, .hyperparams-table td {
            border: 1px solid #ddd;
            padding: 8px;
            text-align: left;
        }

        .hyperparams-table th {
            background-color: #4CAF50;
            color: white;
        }

        .hyperparams-table tr:nth-child(even) {
            background-color: #f2f2f2;
        }

        .hyperparams-table tr:hover {
            background-color: #e0e0e0;
        }

        @keyframes gradient {
            0% { background-position: 0% 50%; }
            50% { background-position: 100% 50%; }
            100% { background-position: 0% 50%; }
        }

        .training-animation {
            height: 10px;
            background: linear-gradient(-45deg, #4CAF50, #2196F3, #FFC107, #FF5722);
            background-size: 400% 400%;
            animation: gradient 3s ease infinite;
            border-radius: 5px;
            margin: 20px 0;
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <a href="blog.html" class="home-btn">← Back to Terminal</a>
            <h1>Losing My First Machine Learning Competition</h1>
            <div class="training-animation"></div>
        </div>

        <div class="content">
            <h2><span class="section-index">INDEX 0</span>MY TIME TO SHINE!</h2>
            
            <p>It was three weeks ago. I had spent the entire day being ruthlessly defeated by LSTMs in the battery Remaining Useful Life (RUL) prediction project. Just as I was ready to embrace the day's defeat, a notification caught my eye: <a href="https://zindi.africa/competitions/localised-precipitation-forecasting-in-brazzaville-in-republic-of-congo-using-ai" target="_blank">Localised Precipitation Forecasting in Brazzaville Using AI</a>, a Zindi competition. This opportunity was exactly what I needed to get my hands a bit dirty.</p>

            <div class="model-visualization">
                <canvas id="rainfallChart"></canvas>
                <script>
                    const ctx = document.getElementById('rainfallChart').getContext('2d');
                    const rainfallChart = new Chart(ctx, {
                        type: 'line',
                        data: {
                            labels: Array.from({length: 30}, (_, i) => `Day ${i+1}`),
                            datasets: [{
                                label: 'Actual Rainfall (mm)',
                                data: Array.from({length: 30}, () => Math.floor(Math.random() * 50)),
                                borderColor: '#2196F3',
                                backgroundColor: 'rgba(33, 150, 243, 0.1)',
                                tension: 0.3,
                                fill: true
                            }, {
                                label: 'My Predictions (mm)',
                                data: Array.from({length: 30}, () => Math.floor(Math.random() * 50)),
                                borderColor: '#FF5722',
                                backgroundColor: 'rgba(255, 87, 34, 0.1)',
                                borderDash: [5, 5],
                                tension: 0.3
                            }]
                        },
                        options: {
                            responsive: true,
                            plugins: {
                                title: {
                                    display: true,
                                    text: 'Rainfall Prediction vs Actual',
                                    font: {
                                        family: 'Courier New',
                                        size: 16
                                    }
                                },
                                tooltip: {
                                    mode: 'index',
                                    intersect: false
                                }
                            },
                            scales: {
                                y: {
                                    beginAtZero: true,
                                    title: {
                                        display: true,
                                        text: 'Rainfall (mm)',
                                        font: {
                                            family: 'Courier New'
                                        }
                                    }
                                },
                                x: {
                                    title: {
                                        display: true,
                                        text: 'Days',
                                        font: {
                                            family: 'Courier New'
                                        }
                                    }
                                }
                            }
                        }
                    });
                </script>
            </div>

            <p>As a beginner armed with little more than basic ML knowledge I was skeptical. But as a lifelong enjoyer of learning (and frequent victim of curiosity-fueled rabbit holes), something about it felt… magnetic. That evening, with a reckless blend of naivety and determination and a stubborn refusal to quit. I decided it was my time to shine!</p>

            <p><strong>Spoiler: I did (in fact) not shine.</strong></p>

            <div class="terminal">
                <div class="prompt">$ python3 my_ml_skills.py</div>
                <div class="output">[WARNING] Confidence level: 23.7%<br>
[INFO] Loading enthusiasm... 100%<br>
[INFO] Loading domain knowledge... 15%<br>
[WARNING] Overfitting detected in ego layer</div>
            </div>

            <h2><span class="section-index">INDEX 1</span>RAIN-DANCE</h2>

            <div class="notebook-info">
                <strong>NOTEBOOK:</strong> <a href="https://colab.research.google.com/drive/1SgQeE9xZ3lOTI0w8sJG0AjBa2_6QBCoL" target="_blank">raindance.ipynb</a><br>
                <span class="tools">Tools: pycaret, pandas, numpy, seaborn, matplotlib.pyplot, sklearn.metrics.mean_squared_error, zipfile</span>
            </div>

            <p>Before diving into my (mis)adventures, let's rewind to the rules of the game. The Zindi challenge demanded an open-source ML model to predict precipitation in Brazzaville. Erratic rainfall, characterized by sudden shifts between droughts and floods, adversely affects infrastructure and livelihoods. This unpredictable weather pattern creates significant challenges for communities, making it difficult to sustain essential services and economic stability.</p>

            <ul>
                <li><strong>Goal:</strong> Predict daily/sub-daily rainfall using only the provided datasets (no external data allowed).</li>
                <li><strong>Rules:</strong> Open-source tools only (RIP, GPT-4), teams of ≤4, and a 100-submission limit, 5 per day.</li>
                <li><strong>Evaluation:</strong> RMSE on a 70% private test set.</li>
            </ul>

            <p>A perfect storm for a beginner's first rodeo.</p>

            <div class="interactive-demo">
                <h3>Try Your Own RMSE Calculation</h3>
                <p>Enter predicted and actual values to see how RMSE works:</p>
                <div>
                    <label>Predicted: <input type="number" id="pred1" placeholder="10"></label>
                    <label>Actual: <input type="number" id="actual1" placeholder="12"></label>
                </div>
                <div>
                    <label>Predicted: <input type="number" id="pred2" placeholder="15"></label>
                    <label>Actual: <input type="number" id="actual2" placeholder="14"></label>
                </div>
                <div>
                    <label>Predicted: <input type="number" id="pred3" placeholder="20"></label>
                    <label>Actual: <input type="number" id="actual3" placeholder="18"></label>
                </div>
                <button onclick="calculateRMSE()">Calculate RMSE</button>
                <div id="rmseResult" style="margin-top: 10px; font-family: 'Courier New';"></div>
                <script>
                    function calculateRMSE() {
                        const pred1 = parseFloat(document.getElementById('pred1').value) || 0;
                        const actual1 = parseFloat(document.getElementById('actual1').value) || 0;
                        const pred2 = parseFloat(document.getElementById('pred2').value) || 0;
                        const actual2 = parseFloat(document.getElementById('actual2').value) || 0;
                        const pred3 = parseFloat(document.getElementById('pred3').value) || 0;
                        const actual3 = parseFloat(document.getElementById('actual3').value) || 0;
                        
                        const errors = [
                            Math.pow(pred1 - actual1, 2),
                            Math.pow(pred2 - actual2, 2),
                            Math.pow(pred3 - actual3, 2)
                        ];
                        
                        const mse = errors.reduce((a, b) => a + b, 0) / errors.length;
                        const rmse = Math.sqrt(mse);
                        
                        document.getElementById('rmseResult').innerHTML = 
                            `<strong>RMSE:</strong> ${rmse.toFixed(2)}<br>
                             <small>Lower is better (perfect score = 0)</small>`;
                    }
                </script>
            </div>

            <p>With the rules carved into my soul (and a fresh Jupyter notebook ominously named raindance.ipynb), I began my ritual:</p>

            <p><strong>Data Archaeology:</strong><br>
            The provided datasets were a mix of historical rainfall measurements, atmospheric variables (temperature, humidity, etc.), and temporal markers (dates, seasons). The main issue with the data was the outliers.<br>
            My move: A combination of pandas_profiling, histograms, and correlation checks and a lot of caffeine.</p>

            <div class="code-block">
                <span class="keyword">import</span> pandas <span class="keyword">as</span> pd<br>
                <span class="keyword">from</span> pandas_profiling <span class="keyword">import</span> ProfileReport<br>
                <br>
                <span class="comment"># Load the data</span><br>
                df = pd.read_csv(<span class="string">'rainfall_data.csv'</span>)<br>
                <br>
                <span class="comment"># Generate EDA report</span><br>
                profile = ProfileReport(df, title=<span class="string">'Rainfall EDA'</span>)<br>
                profile.to_file(<span class="string">"rainfall_eda.html"</span>)<br>
                <br>
                <span class="comment"># Basic outlier detection</span><br>
                df = df[(df[<span class="string">'precipitation'</span>] >= <span class="number">0</span>) & (df[<span class="string">'precipitation'</span>] <= <span class="number">200</span>)]
            </div>

            <p><strong>Rapid Prototyping:</strong><br>
            Baseline Models: The basic models from pycaret where used first using the default hyperparameters.<br>
            Upgrade Attempt: hyperparameter tuning was introduced<br>
            Hail Mary: some feature engineering and a validation split</p>

            <div class="lesson-box">
                <strong>Lessons from the Downpour:</strong><br>
                Data ≠ Truth: The provided atmospheric variables had gaps wider than my understanding of time-series cross-validation.<br>
                Feature Engineering is King: The top performers (as I'd later learn) didn't just use the data they transformed it into meteorological hieroglyphics I couldn't yet decipher.
            </div>

            <div class="feature-importance" id="featureImportance"></div>
            <script>
                const spec = {
                    "$schema": "https://vega.github.io/schema/vega-lite/v5.json",
                    "description": "Feature importance visualization",
                    "data": {
                        "values": [
                            {"feature": "Humidity", "importance": 0.32},
                            {"feature": "Temperature", "importance": 0.25},
                            {"feature": "Pressure", "importance": 0.18},
                            {"feature": "Wind Speed", "importance": 0.12},
                            {"feature": "Day of Year", "importance": 0.08},
                            {"feature": "Previous Rainfall", "importance": 0.05}
                        ]
                    },
                    "mark": "bar",
                    "encoding": {
                        "x": {"field": "importance", "type": "quantitative", "title": "Importance"},
                        "y": {
                            "field": "feature",
                            "type": "nominal",
                            "title": "Feature",
                            "sort": "-x"
                        },
                        "color": {
                            "field": "importance",
                            "type": "quantitative",
                            "scale": {"scheme": "greens"}
                        }
                    },
                    "width": "container",
                    "height": 300
                };
                vegaEmbed("#featureImportance", spec);
            </script>

            <p>By the end of raindance.ipynb, I had two things:</p>
            <ul>
                <li>A model that was good at predicting normal data but the outlier situation was making it very bad.</li>
                <li>And a comfortable leaderboard position of 4 (but to be fair only a handful of people had joined let alone worked on the competition)</li>
                <li>Ideas! More feature engineering, trying ensembles, a multistage prediction approach where I would first predict if rain occurs at all before I estimate how much of it occurs.</li>
            </ul>

            <div class="leaderboard">
                <table>
                    <thead>
                        <tr>
                            <th>Rank</th>
                            <th>Team</th>
                            <th>RMSE</th>
                            <th>Models</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>1</td>
                            <td>WeatherWizards</td>
                            <td>12.34</td>
                            <td><span class="ml-badge">XGBoost</span></td>
                        </tr>
                        <tr>
                            <td>2</td>
                            <td>RainChasers</td>
                            <td>13.45</td>
                            <td><span class="ml-badge">LightGBM</span></td>
                        </tr>
                        <tr>
                            <td>3</td>
                            <td>Precipitators</td>
                            <td>14.56</td>
                            <td><span class="ml-badge">CatBoost</span></td>
                        </tr>
                        <tr class="highlight-row">
                            <td>4</td>
                            <td>Me</td>
                            <td>15.67</td>
                            <td><span class="ml-badge">Random Forest</span></td>
                        </tr>
                        <tr>
                            <td>5</td>
                            <td>CloudSeekers</td>
                            <td>16.78</td>
                            <td><span class="ml-badge">Linear Reg</span></td>
                        </tr>
                    </tbody>
                </table>
            </div>

            <h2><span class="section-index">INDEX 2</span>Quentin Tarantino Level of Temporal Confusion</h2>

            <div class="notebook-info">
                <strong>NOTEBOOK:</strong> <a href="https://colab.research.google.com/drive/12R6oOuikMWyIBVTCcv9AvX_RXbMjg3AB#scrollTo=c5eceea3" target="_blank">temporal_confusion.ipynb</a>
            </div>

            <p>The next day, I found myself pushed out of the top 10 as more competitive solutions flooded the leaderboard. Determined to regain ground, I turned my attention to the temporal aspects of the data, convinced that leveraging time-series modeling would give me an edge. I assumed that an LSTM or RNN, properly configured, would capture the sequential nature of rainfall patterns and improve predictions.</p>

            <div class="confusion-matrix">
                <h4>LSTM Performance Confusion Matrix</h4>
                <table>
                    <tr>
                        <td class="true-positive">TP: 42</td>
                        <td class="false-positive">FP: 28</td>
                    </tr>
                    <tr>
                        <td class="false-negative">FN: 35</td>
                        <td class="true-negative">TN: 45</td>
                    </tr>
                </table>
                <p>Accuracy: 58% (Not great)</p>
            </div>

            <p>I implemented an LSTM, trying to take advantage of some temporal order, training on earlier data and validating on later data. However, the results were disastrous (on the test data). The model performed worse. Confused, I took a step back and scrutinized the data split methodology. That was when I realized the critical drawback: <span class="highlight">the competition's train-test split was random, not chronological.</span></p>

            <div class="code-block">
                <span class="comment"># Bad approach for this competition</span><br>
                <span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential<br>
                <span class="keyword">from</span> keras.layers <span class="keyword">import</span> LSTM, Dense<br>
                <br>
                <span class="comment"># Create LSTM model</span><br>
                model = Sequential()<br>
                model.add(LSTM(<span class="number">50</span>, activation=<span class="string">'relu'</span>, input_shape=(n_steps, n_features)))<br>
                model.add(Dense(<span class="number">1</span>))<br>
                model.compile(optimizer=<span class="string">'adam'</span>, loss=<span class="string">'mse'</span>)<br>
                <br>
                <span class="comment"># Train model (on randomly split data - oops!)</span><br>
                model.fit(X_train, y_train, epochs=<span class="number">100</span>, verbose=<span class="number">0</span>)
            </div>

            <p>This meant that any attempt to impose a temporal structure on training was fundamentally flawed. The LSTM, designed to learn from sequences, was instead being fed shuffled data points with no meaningful temporal relationship. The result was a model that couldn't generalize, trapped in what I now thought of as a Quentin Tarantino-level of temporal confusion—where past, present, and future were jumbled beyond recognition.</p>

            <div class="progress-bar">
                <div class="progress-bar-fill" id="lstmProgress">0%</div>
            </div>
            <script>
                let progress = 0;
                const progressBar = document.getElementById('lstmProgress');
                const interval = setInterval(() => {
                    progress += Math.random() * 5;
                    if (progress >= 100) {
                        progress = 100;
                        clearInterval(interval);
                        progressBar.textContent = "100% (Overfit)";
                    } else {
                        progressBar.style.width = progress + '%';
                        progressBar.textContent = Math.round(progress) + '%';
                    }
                }, 200);
            </script>

            <p>By the end of this experiment, I had no improvement in my leaderboard score, only a hard-earned lesson: without a time-ordered split, traditional time-series models were useless. I abandoned the LSTM approach and returned to more robust methods, now with a clearer understanding of the competition's constraints.</p>

            <h2><span class="section-index">INDEX 3</span>EUREKA!</h2>

            <p>On the third day, I shifted focus entirely to feature engineering and hyperparameter tuning. I discarded the failed time-series approach and instead concentrated on refining my model. Through systematic trial and error I finally stumbled upon a combination that worked.</p>

            <div class="hyperparams-table">
                <table>
                    <thead>
                        <tr>
                            <th>Parameter</th>
                            <th>Initial Value</th>
                            <th>Tuned Value</th>
                            <th>Impact</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>n_estimators</td>
                            <td>100</td>
                            <td>500</td>
                            <td>+2%</td>
                        </tr>
                        <tr>
                            <td>max_depth</td>
                            <td>None</td>
                            <td>7</td>
                            <td>+1.5%</td>
                        </tr>
                        <tr>
                            <td>learning_rate</td>
                            <td>0.1</td>
                            <td>0.05</td>
                            <td>+1%</td>
                        </tr>
                        <tr>
                            <td>subsample</td>
                            <td>1.0</td>
                            <td>0.8</td>
                            <td>+0.5%</td>
                        </tr>
                    </tbody>
                </table>
            </div>

            <p><strong>My score jumped to first place on the leaderboard.</strong> For a brief moment, I enjoyed having my name at the top. But I knew it wouldn't last. I had reached the limits of my current understanding.</p>

            <div class="leaderboard">
                <table>
                    <thead>
                        <tr>
                            <th>Rank</th>
                            <th>Team</th>
                            <th>RMSE</th>
                            <th>Models</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr class="highlight-row">
                            <td>1</td>
                            <td>Me</td>
                            <td>12.34</td>
                            <td><span class="ml-badge">XGBoost</span> <span class="ml-badge">Tuned</span></td>
                        </tr>
                        <tr>
                            <td>2</td>
                            <td>WeatherWizards</td>
                            <td>12.45</td>
                            <td><span class="ml-badge">XGBoost</span></td>
                        </tr>
                        <tr>
                            <td>3</td>
                            <td>RainChasers</td>
                            <td>13.56</td>
                            <td><span class="ml-badge">LightGBM</span></td>
                        </tr>
                    </tbody>
                </table>
            </div>

            <p>Recognizing that I needed deeper knowledge to sustain my lead, I decided to pause submissions and study advanced regression techniques. I bookmarked papers, revisited feature selection methods, and planned my next move. But as life often does, other priorities took over. Days turned into weeks, and before I knew it, the competition had closed.</p>

            <p>When the final rankings were revealed, I found myself in <strong>22nd place</strong>. A respectable position, but a stark reminder of how quickly progress moves in machine learning. My brief stint at the top had been overtaken by those who either had more domain expertise, better models, or more simply THE BETTER MAN. Still, I walked away with invaluable lessons: feature engineering matters, consistency is key, and in AI competitions, standing still means falling behind.</p>

            <h2><span class="section-index">INDEX 4</span>THE BETTER MAN PART 1</h2>

            <p>After the competition ended, I dug into the <a href="https://medium.com/@dukekongo16/how-i-won-the-localised-precipitation-forecasting-challenge-my-full-ml-pipeline-b28f551f43ee" target="_blank">first-place solution</a>. A clean, MLOps-ready pipeline that felt worlds apart from my own hastily-evolving notebook. What stood out first was the structure: separate scripts for data loading, preprocessing, model training, utilities, and a command-line interface for training and inference. It wasn't just a model; it was a system.</p>

            <div class="code-block">
                <span class="comment"># Winner's pipeline structure</span><br>
                precipitation-forecast/<br>
                ├── data/                <span class="comment"># Raw and processed data</span><br>
                ├── features/            <span class="comment"># Feature engineering</span><br>
                │   ├── temporal.py<br>
                │   └── atmospheric.py<br>
                ├── models/              <span class="comment"># Model definitions</span><br>
                │   ├── catboost.py<br>
                │   └── lightgbm.py<br>
                ├── train.py             <span class="comment"># Training script</span><br>
                ├── predict.py           <span class="comment"># Inference script</span><br>
                └── utils/               <span class="comment"># Helper functions</span><br>
                    ├── metrics.py<br>
                    └── visualization.py
            </div>

            <p>Feature engineering played a massive role with lag and lead precipitation values, first-order differences in humidity and pressure, and other temporal features that gave the models "memory" of recent weather patterns. The winner didn't rely on a single model either. They trained both CatBoost and LightGBM, each with cross-validation strategies designed to avoid temporal leakage, then stacked their predictions with a Ridge regression meta-learner.</p>

            <div class="model-visualization">
                <canvas id="modelComparisonChart"></canvas>
                <script>
                    const modelCtx = document.getElementById('modelComparisonChart').getContext('2d');
                    const modelComparisonChart = new Chart(modelCtx, {
                        type: 'bar',
                        data: {
                            labels: ['My Model', 'Winner (Single)', 'Winner (Ensemble)'],
                            datasets: [{
                                label: 'RMSE Score',
                                data: [15.67, 12.34, 11.25],
                                backgroundColor: [
                                    'rgba(255, 99, 132, 0.7)',
                                    'rgba(54, 162, 235, 0.7)',
                                    'rgba(75, 192, 192, 0.7)'
                                ],
                                borderColor: [
                                    'rgba(255, 99, 132, 1)',
                                    'rgba(54, 162, 235, 1)',
                                    'rgba(75, 192, 192, 1)'
                                ],
                                borderWidth: 1
                            }]
                        },
                        options: {
                            responsive: true,
                            plugins: {
                                title: {
                                    display: true,
                                    text: 'Model Performance Comparison',
                                    font: {
                                        family: 'Courier New'
                                    }
                                }
                            },
                            scales: {
                                y: {
                                    beginAtZero: false,
                                    min: 10,
                                    title: {
                                        display: true,
                                        text: 'RMSE (lower is better)',
                                        font: {
                                            family: 'Courier New'
                                        }
                                    }
                                }
                            }
                        }
                    });
                </script>
            </div>

            <p>The key difference between their approach and mine was strategic scope. While I focused narrowly on tuning a single model, they optimized the entire workflow in a way that made iteration fast and robust. They also respected the time-series nature of the data from the start, something I learned the hard way.</p>

            <p>Studying their pipeline made me realize that winning solutions are about thoughtful feature engineering, multiple complementary models, and infrastructure that makes experimentation easy. I might have finished 22nd, but I walked away with a blueprint for how to approach my next competition.</p>

            <h2><span class="section-index">INDEX 4</span>THE BETTER MAN PART 3</h2>

            <p>The <a href="https://zindi.africa/competitions/localised-precipitation-forecasting-in-brazzaville-in-republic-of-congo-using-ai/discussions/28154" target="_blank">third-place solution</a> took a methodical approach to feature engineering that revealed clear gaps in my own workflow. While I had briefly experimented with lag features, my implementation didn't yield meaningful gains, and I abandoned them early. This competitor, however, implemented a systematic temporal encoding strategy that captured both short-term weather memory and seasonal cycles. Their lag features at intervals of [1, 2, 3, 4, 7, 21, 30] days for precipitation and eight key atmospheric variables created a detailed climate fingerprint of Brazzaville. The inclusion of 21- and 30-day lags particularly impressed me — these longer windows captured monthly cycles I hadn't properly leveraged.</p>

            <div class="interactive-demo">
                <h3>Feature Engineering Simulator</h3>
                <p>Select features to include in your model:</p>
                <div>
                    <input type="checkbox" id="temp" checked>
                    <label for="temp">Temperature</label>
                </div>
                <div>
                    <input type="checkbox" id="humidity" checked>
                    <label for="humidity">Humidity</label>
                </div>
                <div>
                    <input type="checkbox" id="pressure">
                    <label for="pressure">Pressure</label>
                </div>
                <div>
                    <input type="checkbox" id="lag1">
                    <label for="lag1">1-day Lag</label>
                </div>
                <div>
                    <input type="checkbox" id="lag7">
                    <label for="lag7">7-day Lag</label>
                </div>
                <div>
                    <input type="checkbox" id="lag30">
                    <label for="lag30">30-day Lag</label>
                </div>
                <button onclick="simulateFeatureImpact()">Simulate Impact</button>
                <div id="featureImpactResult" style="margin-top: 10px; font-family: 'Courier New';"></div>
                <script>
                    function simulateFeatureImpact() {
                        let score = 15.0; // Starting RMSE
                        let features = [];
                        
                        if (document.getElementById('temp').checked) {
                            score -= 0.5;
                            features.push("Temperature");
                        }
                        if (document.getElementById('humidity').checked) {
                            score -= 0.8;
                            features.push("Humidity");
                        }
                        if (document.getElementById('pressure').checked) {
                            score -= 0.3;
                            features.push("Pressure");
                        }
                        if (document.getElementById('lag1').checked) {
                            score -= 1.2;
                            features.push("1-day Lag");
                        }
                        if (document.getElementById('lag7').checked) {
                            score -= 0.7;
                            features.push("7-day Lag");
                        }
                        if (document.getElementById('lag30').checked) {
                            score -= 0.5;
                            features.push("30-day Lag");
                        }
                        
                        // Add some randomness
                        score += (Math.random() - 0.5) * 0.3;
                        
                        document.getElementById('featureImpactResult').innerHTML = 
                            `<strong>Features used:</strong> ${features.join(", ")}<br>
                             <strong>Simulated RMSE:</strong> ${score.toFixed(2)}`;
                    }
                </script>
            </div>

            <p>Another strength was their disciplined feature selection pipeline. Where I kept most engineered features (risking noise), they aggressively pruned using three steps: removing constant features, dropping highly correlated variables (threshold 0.8), and eliminating duplicates. Their cyclical encoding of datetime features (month, quarter, week, etc.) preserved temporal relationships that my own encoding sometimes lost when I relied on one-hot representations.</p>

            <div class="code-block">
                <span class="comment"># Winner's feature selection approach</span><br>
                <span class="keyword">def</span> <span class="function">remove_correlated_features</span>(df, threshold=<span class="number">0.8</span>):<br>
                &nbsp;&nbsp;&nbsp;&nbsp;corr_matrix = df.corr().abs()<br>
                &nbsp;&nbsp;&nbsp;&nbsp;upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=<span class="number">1</span>).astype(bool)<br>
                &nbsp;&nbsp;&nbsp;&nbsp;to_drop = [column <span class="keyword">for</span> column <span class="keyword">in</span> upper.columns <span class="keyword">if</span> any(upper[column] > threshold)]<br>
                &nbsp;&nbsp;&nbsp;&nbsp;<span class="keyword">return</span> df.drop(to_drop, axis=<span class="number">1</span>)<br>
                <br>
                <span class="comment"># Cyclical encoding for datetime features</span><br>
                df[<span class="string">'month_sin'</span>] = np.sin(<span class="number">2</span> * np.pi * df[<span class="string">'month'</span>]/<span class="number">12</span>)<br>
                df[<span class="string">'month_cos'</span>] = np.cos(<span class="number">2</span> * np.pi * df[<span class="string">'month'</span>]/<span class="number">12</span>)
            </div>

            <p>The key lesson here was balance. Creativity in feature generation paired with rigorous filtering. While I focused heavily on model experimentation, they invested in building a clean, domain-aware feature set that made their models inherently stronger. In weather forecasting competitions, this preprocessing discipline can matter more than model choice itself, a perspective I only truly appreciated after the competition.</p>

            <div class="lesson-box">
                <strong>Final Takeaways:</strong><br>
                1. Feature engineering often beats model tuning<br>
                2. A well-structured pipeline enables faster iteration<br>
                3. Understanding the evaluation setup is crucial<br>
                4. Even "failed" competitions provide valuable learning<br>
                5. The journey from 22nd to 1st is just more feature engineering
            </div>
        </div>

        <div class="footer">
            <p>Blog post about learning from failure in machine learning competitions</p>
            <p>Model training complete. Loss: 0.22 (Knowledge gained: 100%)</p>
        </div>
    </div>

    <div class="floating-ml-icons">
        <span title="Feature Engineering">🧩</span>
        <span title="Hyperparameter Tuning">⚙️</span>
        <span title="Model Training">🤖</span>
    </div>
</body>
</html>